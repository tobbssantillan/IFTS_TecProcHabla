{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adFzzFsB-Ofl"
      },
      "source": [
        "<h1>Explorando el Interior de Modelos de Lenguaje Transformer</h1>\n",
        "<i>Un análisis profundo de la arquitectura transformer en modelos generativos de lenguaje</i>\n",
        "\n",
        "---\n",
        "\n",
        "Este cuaderno está adaptado del Capítulo 3 del libro [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9o0Yc3QNsY6"
      },
      "source": [
        "### [OPCIONAL] - Instalación de Paquetes en <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
        "\n",
        "Si estás ejecutando este cuaderno en Google Colab, necesitas **descomentar y ejecutar** el siguiente bloque de código para instalar las dependencias:\n",
        "\n",
        "---\n",
        "\n",
        "💡 **NOTA**: Para mejores resultados, usa una GPU. En Google Colab, ve a:\n",
        "**Entorno de ejecución > Cambiar tipo de entorno de ejecución > Acelerador de hardware > GPU > Tipo de GPU > T4**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rDQT1WFoNsY7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers>=4.41.2 accelerate>=0.31.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_23Z_do-faF"
      },
      "source": [
        "# Cargando el Modelo de Lenguaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-5RLd6dI-Ytm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "24dff171fc43410e9c3b29e4b6e3022b",
            "685c13eda93b4e0cbbdaf37d8a01c815",
            "e6ac0040228342f5998ddbd4c2f94d7c",
            "0677719a35c04bf7b7d390b7767dd0a7",
            "477aca468a3243d48af31f321636ad1c",
            "9863a98e644c4f93937009ee3a51ee79",
            "6f51f854e6b5432d9818b5c35909d28e",
            "05232868d6c14c9d9a67d9db863fcd57",
            "b0384c194c7a49f7bd1b0fa8d380f1ac",
            "6b6798d91681411ebef03baa4d43d450",
            "c9cb79da5d9f43bcbe754d845f006bb2"
          ]
        },
        "outputId": "625af1e6-6fde-46e2-e060-be2d10d27b4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24dff171fc43410e9c3b29e4b6e3022b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Cargar modelo y tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un pipeline de generación de texto\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=200,\n",
        "    do_sample=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc76gtdiMFZ5",
        "outputId": "f8e6fc9f-1c51-462c-d328-dd313bb31712"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REqcz-ID_XgV"
      },
      "source": [
        "# Entradas y Salidas de un Modelo Transformer Entrenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "17h6TPHluJ-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e88686-51ea-4ba6-fec3-4c03adae4d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "### Solution:\n",
            "\n",
            "Mensaje a Juan:\n",
            "\n",
            "\n",
            "Querido Juan,\n",
            "\n",
            "\n",
            "Espero que este mensaje te encuentre bien. Me pongo en contacto contigo porque quiero compartir algo importante y, aunque no es la manera más romántica, creo que es esencial que lo hagamos de esta forma.\n",
            "\n",
            "\n",
            "Recuerdo nuestras últimas vacaciones en la playa, cuando nos encontramos por casualidad y, en un momento de distracción, me pisó el pie. Fue un incidente inofensivo, pero me sentí muy mal por haberlo hecho.\n",
            "\n",
            "\n",
            "Quería expresarte que me siento muy arrepentido por mi comportamiento. No tenía la intención de causarte molestia y me apena mucho haberte hecho sentir incómodo. Espero que puedas perdon\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo adaptado al contexto argentino\n",
        "prompt = \"Mandale un mensajito a Juan pidiéndole perdón por haberle pisado el pie en el bondi. Explicale qué pasó, pero sin chamuyo.\"\n",
        "\n",
        "output = generator(prompt)\n",
        "\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eoFkdTd6_g5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3bc1d0-5a8a-4493-8c2f-574201059012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phi3ForCausalLM(\n",
            "  (model): Phi3Model(\n",
            "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x Phi3DecoderLayer(\n",
            "        (self_attn): Phi3Attention(\n",
            "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
            "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
            "        )\n",
            "        (mlp): Phi3MLP(\n",
            "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
            "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
            "          (activation_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
            "        (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
            "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
            "    (rotary_emb): Phi3RotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Mostrar la arquitectura del modelo\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTrwzB67BYVY"
      },
      "source": [
        "# Seleccionando un token de la distribución de probabilidades (sampling/decoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sEcxYgJxBYbJ"
      },
      "outputs": [],
      "source": [
        "prompt = \"La universidad más prestigiosa del mundo es la Universidad de\"\n",
        "\n",
        "# Tokenizar el prompt de entrada\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "input_ids = input_ids.to(\"cuda\")\n",
        "\n",
        "# Obtener la salida del modelo antes de la capa lm_head\n",
        "model_output = model.model(input_ids)\n",
        "\n",
        "# Obtener la salida de la capa lm_head\n",
        "lm_head_output = model.lm_head(model_output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "68YUSS4GBf9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3f1454b2-f80d-41eb-f2b4-b91f16a633d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harvard'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Obtener el token con mayor probabilidad\n",
        "token_id = lm_head_output[0,-1].argmax(-1)\n",
        "tokenizer.decode(token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2_rP4QBqrZ"
      },
      "source": [
        "# Acelerando la generación con caché de keys y values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B0n6JhNHBrin"
      },
      "outputs": [],
      "source": [
        "prompt = \"Escribe una carta muy larga explicando por qué el asado del domingo se quemó. Describe qué salió mal.\"\n",
        "\n",
        "# Tokenizar el prompt de entrada\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "input_ids = input_ids.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BwIvt6jSByAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26523089-a8e7-4825-fabe-e89a51ab3bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.67 s ± 2.29 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 1\n",
        "# Generar texto con caché activado\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=100,\n",
        "  use_cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dFb1dcvJByCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b21b8c-c522-4e73-c384-8991993340bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 s ± 406 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 1\n",
        "# Generar texto con caché desactivado\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=100,\n",
        "  use_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwhrXCgpNsY-"
      },
      "source": [
        "# Explicación\n",
        "\n",
        "## ¿Qué aprendimos?\n",
        "\n",
        "1. **Carga de modelos**: Cargamos el modelo Phi-3-mini, un modelo de lenguaje eficiente y potente.\n",
        "2. **Generación de texto**: Vimos cómo el modelo puede generar texto coherente en español con ejemplos locales.\n",
        "3. **Arquitectura interna**: Exploramos la estructura del modelo transformer.\n",
        "4. **Proceso de decodificación**: Analizamos cómo el modelo selecciona la siguiente palabra.\n",
        "5. **Optimización**: Comparamos el rendimiento con y sin caché de atención.\n",
        "\n",
        "## Aplicaciones\n",
        "\n",
        "Estos modelos pueden usarse para:\n",
        "- Generar contenido educativo en español rioplatense\n",
        "- Analizar textos legales y normativas locales\n",
        "- Crear asistentes virtuales con conocimiento de cultura argentina\n",
        "- Procesar documentos históricos y literarios nacionales"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24dff171fc43410e9c3b29e4b6e3022b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_685c13eda93b4e0cbbdaf37d8a01c815",
              "IPY_MODEL_e6ac0040228342f5998ddbd4c2f94d7c",
              "IPY_MODEL_0677719a35c04bf7b7d390b7767dd0a7"
            ],
            "layout": "IPY_MODEL_477aca468a3243d48af31f321636ad1c"
          }
        },
        "685c13eda93b4e0cbbdaf37d8a01c815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9863a98e644c4f93937009ee3a51ee79",
            "placeholder": "​",
            "style": "IPY_MODEL_6f51f854e6b5432d9818b5c35909d28e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e6ac0040228342f5998ddbd4c2f94d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05232868d6c14c9d9a67d9db863fcd57",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0384c194c7a49f7bd1b0fa8d380f1ac",
            "value": 2
          }
        },
        "0677719a35c04bf7b7d390b7767dd0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6798d91681411ebef03baa4d43d450",
            "placeholder": "​",
            "style": "IPY_MODEL_c9cb79da5d9f43bcbe754d845f006bb2",
            "value": " 2/2 [00:39&lt;00:00, 18.82s/it]"
          }
        },
        "477aca468a3243d48af31f321636ad1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9863a98e644c4f93937009ee3a51ee79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f51f854e6b5432d9818b5c35909d28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05232868d6c14c9d9a67d9db863fcd57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0384c194c7a49f7bd1b0fa8d380f1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b6798d91681411ebef03baa4d43d450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9cb79da5d9f43bcbe754d845f006bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}