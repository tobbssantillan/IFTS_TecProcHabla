# -*- coding: utf-8 -*-
"""tph_text_mining_imdb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aWr9DptV1xWNP6Kvokkltk22urvDAtpp
"""

# Importamos librerías.
from google.colab import drive
import requests
from bs4 import BeautifulSoup
import pandas as pd
import spacy
import nltk
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
from collections import Counter
from nltk.probability import ConditionalFreqDist

# Montamos Google Drive.
drive.mount('/content/drive')

# Creamos diccionario donde almacenamos las urls.
urls = {
    "The Irishman": "https://www.imdb.com/title/tt1302006/reviews/?sort=num_votes%2Cdesc&spoilers=EXCLUDE",
    "Shutter Island": "https://www.imdb.com/title/tt1130884/reviews/?ref_=tturv_ql_2&sort=num_votes%2Cdesc&spoilers=EXCLUDE",
    "The Wolf of Wall Street": "https://www.imdb.com/title/tt0993846/reviews/?ref_=tt_ururv_sm&sort=num_votes%2Cdesc&spoilers=EXCLUDE",
    "Raging Bull": "https://www.imdb.com/title/tt0081398/reviews/?ref_=tt_ururv_sm&sort=num_votes%2Cdesc&spoilers=EXCLUDE",
    "Taxi Driver": "https://www.imdb.com/title/tt0075314/reviews/?ref_=tt_ururv_sm&sort=num_votes%2Cdesc&spoilers=EXCLUDE",
    "Goodfellas": "https://www.imdb.com/title/tt0099685/reviews/?ref_=tt_ururv_sm&sort=num_votes%2Cdesc&spoilers=EXCLUDE",
}

# User-Agent para evitar bloqueos por parte de IMDb
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
}

def get_reviews(url):
  reviews = []

  # Obtenemos el contenido HTML de la URL
  res = requests.get(url, headers=headers)
  soup = BeautifulSoup(res.text, 'html.parser')

  # Buscamos la clase para las resenias
  review_divs = soup.find_all('div', class_='ipc-html-content-inner-div')

  # Extraemos los textos
  for review in review_divs:
    reviews.append(review.get_text(strip=True))

  return reviews

# Scrapeo todas las películas
data = {}
for title, url in urls.items():
    print(f"Scrapeando reseñas de: {title}")
    data[title] = get_reviews(url)
    print(f"Total reseñas : {len(data[title])}\n")

# Guardar CSV en Drive
reviews_df = pd.DataFrame([(movie, review) for movie, reviews in data.items() for review in reviews],
                          columns=["movie", "review"])
reviews_df.to_csv("/content/drive/MyDrive/scorsese_reviews.csv", index=False)
print("Archivo CSV guardado en: /content/drive/MyDrive/scorsese_reviews.csv")
print("Primer reseña de la película", reviews_df['movie'].iloc[0], ":", reviews_df['review'].iloc[0])

nltk.download('stopwords')
nlp = spacy.load("en_core_web_sm")

# Limpiamos el texto
stopwords_nltk = set(stopwords.words('english'))
stopwords_spacy = set(spacy.lang.en.stop_words.STOP_WORDS)
stopwords_custom = set(["movie", "film", "not", "like", "watch", "thing", ])
all_stopwords = stopwords_nltk.union(stopwords_spacy).union(stopwords_custom)

# --- Nueva lista de palabras a eliminar manualmente ---
palabras_a_eliminar = [
    "movie", "film", "story", "character", "scene", "performance",
    "director", "watch", "see", "one", "make", "want", "read", "scorcese",
    "youre", "know", "played", "im", "doesnt", "scorsese", "de niro",
    "pesci", "niro", "dicaprio", "pacino", "de", "martin", "teddy",
    "jordan", "belfort", "lot", "betsy", "joe", "al", "dont", "lamotta",
    "actor", "leonardo", "sex", "goodfellas", "taxi", "driver", "shutter",
    "island", "wolf", "bull", "raging", "robert", "travis", "bickle",
    "scenes", "la motta", "irishman", "wall", "street", "deniro", "movies",
    "films", "watching", "jake", "la", "motta", "cinema", "feel", "seen",
    "bit", "thats", "cast", "way", "use", "think", "fact", "scorseses",
    "saw", "time", "hes", "jimmy", "hoffa", "belforts", "big", "come",
    "ray", "liotta"
    ]

# --- Función de limpieza usando blacklist + stopwords ---
def limpiar_texto_con_blacklist(texto, blacklist):
    black_list = all_stopwords.union(blacklist)
    texto = texto.lower()
    texto = re.sub(r'[^\w\s]', '', texto)
    return ' '.join([palabra for palabra in texto.split() if palabra not in black_list])

# --- Aplicar la limpieza a todas las reseñas ---
reviews_df["clean_review"] = reviews_df["review"].apply(lambda x: limpiar_texto_con_blacklist(x, palabras_a_eliminar))

# Guardamos el corpus limpio

reviews_df.to_csv("/content/drive/MyDrive/scorsese_reviews_clean.csv", index=False)

# Bag of Words

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(reviews_df["clean_review"])
terms = vectorizer.get_feature_names_out()

# Transformamos a DataFrame

bow_df = pd.DataFrame(X.toarray(), columns=terms)
bow_df['movie']  = reviews_df['movie']

top_words_per_movie = {}
for movie in reviews_df['movie'].unique():
  text = " ".join(reviews_df[reviews_df['movie'] == movie]['clean_review'])
  words = text.split()
  counter = Counter(words)
  top_words_per_movie[movie] = counter.most_common(10)

print ("\nTop 10 palabras más frecuentes por película:")
for movie, words in top_words_per_movie.items():
  print(f"{movie}: {words}\n")

# Estadísticas de palabras
unique_words = []
words_per_review = []
for movie in reviews_df['movie'].unique():
    movie_reviews = reviews_df[reviews_df['movie'] == movie]['clean_review']
    all_words = " ".join(movie_reviews).split()
    unique_words.append(len(set(all_words)))
    words_per_review.append(sum(len(r.split()) for r in movie_reviews) / len(movie_reviews))

stats_df = pd.DataFrame({
    'movie': reviews_df['movie'].unique(),
    'unique_words': unique_words,
    'words_per_review': words_per_review
})

print("\nEstadísticas de palabras:")
print(stats_df)

# WordCloud por película en una grilla 2x3
peliculas = reviews_df['movie'].unique()

fig, axes = plt.subplots(2, 3, figsize=(18, 12))  # 2 filas, 3 columnas (ajusté figsize para que se vea mejor)
axes = axes.flatten()  # Aplana la matriz de ejes

for i, movie in enumerate(peliculas):
    text = " ".join(reviews_df[reviews_df['movie'] == movie]['clean_review'])
    wc = WordCloud(
        stopwords=all_stopwords,
        background_color='black',
        colormap='autumn',
        max_words=15
    ).generate(text)
    axes[i].imshow(wc, interpolation='bilinear')
    axes[i].axis('off')
    axes[i].set_title(movie, fontsize=16)


plt.tight_layout()
plt.show()

# Gráficos de barras
plt.figure(figsize=(12,5))
plt.barh(stats_df['movie'], stats_df['unique_words'])
plt.xlabel('Unique Words')
plt.title('Cantidad de Palabras Únicas por Película')
plt.show()

plt.figure(figsize=(12,5))
plt.barh(stats_df['movie'], stats_df['words_per_review'])
plt.xlabel('Words per Review')
plt.title('Promedio de Palabras por Reseña')
plt.show()

# Lista de palabras que quieres analizar
palabras_objetivo = ['life', 'money', 'violence', 'love', 'loneliness', 'drug', 'family']

# Creamos lista (palabra, película) para alimentar al ConditionalFreqDist
palabra_pelicula = []

for pelicula in reviews_df['movie'].unique():
    reseñas = " ".join(reviews_df[reviews_df['movie'] == pelicula]['clean_review'])
    tokens = reseñas.lower().split()
    for palabra in palabras_objetivo:
        palabra_pelicula.extend([(palabra, pelicula) for token in tokens if token.startswith(palabra)])

# Creamos el ConditionalFreqDist
cfd = ConditionalFreqDist(palabra_pelicula)

# Graficamos
cfd.plot(title='Frecuencia de palabras específicas por película', cumulative=False)

"""# --- Conclusiones ---

# 1. Scraping y Análisis de Reseñas:
# Se extrajeron y procesaron reseñas de 6 películas emblemáticas de Martin Scorsese, permitiendo un análisis textual detallado de las percepciones del público.

# 2. WordClouds por Película:
# Cada WordCloud mostró que conceptos como 'life', 'money' y 'violence' son temas recurrentes, aunque cada película tiene sus propias particularidades emocionales y narrativas.

# 3. Estadísticas de Palabras:
# Raging Bull y The Wolf of Wall Street generaron reseñas más extensas y diversas en vocabulario.

# 4. Análisis de Frecuencia de Conceptos:
# El análisis de términos específicos reveló que "life"  domina en todas las películas, lo que conecta con los temas de decadencia, existencialismo y corrupción que caracterizan la filmografía de Scorsese.
"""